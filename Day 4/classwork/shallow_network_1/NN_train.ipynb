{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_value = np.array([[0,0], [0, 1], [1, 1], [1, 0]])\n",
    "output = np.array([0, 1, 1, 0])\n",
    "output = output.reshape(4, 1)\n",
    "\n",
    "input_value.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "def derivative_fun(x):\n",
    "    return sigmoid_function(x) * (1 - sigmoid_function(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data = []\n",
    "\n",
    "def training_shallow_network(input_arr):\n",
    "    weigths = np.array([[0.2], [0.2]])\n",
    "    bias = 0.3\n",
    "    for epoch in range(6000):\n",
    "        # xW + b\n",
    "        weighted_sum = np.dot(input_arr, weigths) +  bias\n",
    "        # g(xW + b)\n",
    "        first_output = sigmoid_function(weighted_sum)\n",
    "        # g'(x) = g(x)(1-g(x))\n",
    "        # y - hj\n",
    "        error = first_output - output\n",
    "        first_der = error\n",
    "        second_der = derivative_fun(first_output)\n",
    "        derivative = first_der * second_der\n",
    "        # loss function update\n",
    "        t_input = input_value.T\n",
    "        final_derivative = np.dot(t_input, derivative)\n",
    "\n",
    "        weigths = weigths - 0.05 * final_derivative\n",
    "\n",
    "        for i in derivative:\n",
    "            bias = bias - 0.05 * i\n",
    "\n",
    "        total_error = np.square(np.subtract(first_output, output)).mean()\n",
    "        error_data.append([1, total_error])\n",
    "    return weigths, bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigths, bias = training_shallow_network(input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training my network\n",
    "weigths, bias = training_shallow_network(input_value)\n",
    "\n",
    "# testing my network\n",
    "pred = np.array([0, 1])\n",
    "result = np.dot(pred, weigths) + bias\n",
    "res = sigmoid_function(result)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "for i, value in enumerate(error_data):\n",
    "    x_axis.append(i)\n",
    "    y_axis.append(value)\n",
    "plt.plot(x_axis, y_axis)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model = {\n",
    "    \"weigths\": weigths,\n",
    "    \"bias\": bias\n",
    "}\n",
    "\n",
    "with open('myshallownetwork.pickle', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

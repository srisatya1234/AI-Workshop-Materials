{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset from \n",
    "# https://github.com/scikit-learn/scikit-learn/blob/4180b079f7709fe5ab8d32a11438116dc8957715/sklearn/datasets/data/iris.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "file_path = '/home/dileepkumar/Z_ISL/workshops/AI-Workshop-Materials/Day 4/classwork/kNN_algorithm/src/iris.csv'\n",
    "# load my dataset\n",
    "data = [row for row in csv.reader(open(file_path))]\n",
    "# removing the csv headers from data\n",
    "data = data[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my data looks like strings, preprocessing data\n",
    "data = [[float(item[0]), float(item[1]), float(item[2]), float(item[3]), int(item[4])]  for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, test_size=0.2):\n",
    "    # random shuffling my data\n",
    "    random.shuffle(data)\n",
    "    total = len(data)\n",
    "    # counting what should be my test samples size\n",
    "    test_samples_size = int(total * test_size)\n",
    "    # seprating test samples and train samples\n",
    "    test_samples = data[:test_samples_size]\n",
    "    train_samples = data[test_samples_size:]\n",
    "    return train_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, test_samples = split_train_test(data, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_samples), len(test_samples), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def euclideandistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    # distance  = sqrt(x^2 + y^2)\n",
    "    for x in range(length):\n",
    "        distance += pow((instance1[x] - instance2[x]), 2)\n",
    "    return math.sqrt(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(trainingset, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance) - 1\n",
    "    for training_instance in (trainingset):\n",
    "        # find the distance\n",
    "        dist = euclideandistance(testInstance, training_instance, length)\n",
    "        # append the class information along with distance\n",
    "        distances.append((training_instance[4], dist))\n",
    "    # sorting along based on distances\n",
    "    distances.sort(key=lambda x:x[1])\n",
    "    neighbours = []\n",
    "    # appending nearest k neighbours\n",
    "    for x in range(k):\n",
    "        neighbours.append(distances[x][0])\n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 \n",
    "neighbours = getNeighbors(train_samples, test_samples[0], k)\n",
    "neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(neighbours).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "k = 7\n",
    "for testInstance in test_samples:\n",
    "    neighbours = getNeighbors(train_samples, testInstance, k)\n",
    "    prediction = Counter(neighbours).most_common(1)[0][0]\n",
    "    actual = testInstance[-1]\n",
    "    preds.append([prediction, actual])\n",
    "\n",
    "#     if actual == prediction:\n",
    "#         preds.append(1)\n",
    "#     else:\n",
    "#         preds.append(0)\n",
    "# accuracy = sum(preds) / len(preds)\n",
    "# accuracy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [item[0] for item in preds]\n",
    "y_actual = [item[1] for item in preds]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_actual, y_pred, labels = [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_actual, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
